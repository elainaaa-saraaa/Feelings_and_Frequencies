>Feelings & Frequencies

Emotion Recognition from Speech Using Classical ML and Signal Processing

>Overview

Feelings & Frequencies is a speech‑emotion recognition system that blends Digital Signal Processing (DSP) with Classical Machine Learning to classify human emotions from a>udio.
Instead of relying on deep learning, this project focuses on feature‑engineered audio analysis, making it lightweight, interpretable, and grounded in core ECE concepts.
The system extracts spectral features from speech, trains a Random Forest classifier, visualizes emotion clusters using PCA, and evaluates robustness under real‑world distortions such as noise, pitch shifts, speed changes, and volume variations.

> Key Features
1. Digital Signal Processing (DSP) Feature Extraction
a. Zero Crossing Rate (ZCR)
b. Spectral Centroid
c. Spectral Bandwidth
d. Spectral Rolloff
These features capture the energy, brightness, sharpness, and frequency spread of speech — all of which vary with emotion.

2. Classical Machine Learning
a. Random Forest classifier
b. Train/test split with stratification
c. Classification report + accuracy metrics
d. Probability‑based emotion prediction



